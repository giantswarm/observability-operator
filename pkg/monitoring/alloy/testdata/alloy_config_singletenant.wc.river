logging {
  level  = "info"
  format = "logfmt"
}

remote.kubernetes.secret "credentials" {
  name      = "alloy-metrics"
  namespace = "kube-system"
}
// load rules for tenant tenant1
mimir.rules.kubernetes "tenant1" {
  address = nonsensitive(remote.kubernetes.secret.credentials.data["mimirRulerAPIURL"])
  basic_auth {
    username   = nonsensitive(remote.kubernetes.secret.credentials.data["mimirRemoteWriteAPIUsername"])
     password = remote.kubernetes.secret.credentials.data["mimirRemoteWriteAPIPassword"]
  }
  extra_query_matchers {
    matcher {
        name       = "cluster_id"
        match_type = "="
        value      = "single-tenant-cluster"
    }
  }
  mimir_namespace_prefix = "single-tenant-cluster"
  tenant_id = "tenant1"
  rule_selector {
      match_labels = {
        "observability.giantswarm.io/tenant" = "tenant1",
      }
      match_expression {
        key = "application.giantswarm.io/prometheus-rule-kind"
        operator = "NotIn"
        values = ["loki"]
      }
  }
}

// we create a podmonitor and servicemonitor component per tenant because we cannot read pod/service monitor labels through relabelling.
// remote write pipeline configuration for tenant tenant1

prometheus.operator.servicemonitors "tenant1" {
  forward_to = [prometheus.remote_write.tenant1.receiver]
  selector {
    match_expression {
      key      = "observability.giantswarm.io/tenant"
      operator = "In"
      values   = ["tenant1"]
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
}

prometheus.operator.podmonitors "tenant1" {
  forward_to = [prometheus.remote_write.tenant1.receiver]
  selector {
    match_expression {
      key      = "observability.giantswarm.io/tenant"
      operator = "In"
      values   = ["tenant1"]
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
}

prometheus.operator.scrapeconfigs "tenant1" {
  forward_to = [prometheus.remote_write.tenant1.receiver]
  selector {
    match_expression {
      key      = "observability.giantswarm.io/tenant"
      operator = "In"
      values   = ["tenant1"]
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
}

// remote write pipeline configuration for tenant tenant1
prometheus.remote_write "tenant1" {
  endpoint {
    url            = nonsensitive(remote.kubernetes.secret.credentials.data["mimirRemoteWriteAPIURL"])
    name           = nonsensitive(remote.kubernetes.secret.credentials.data["mimirRemoteWriteAPIName"])
    enable_http2   = false
    remote_timeout = "60s"
    basic_auth {
      username = nonsensitive(remote.kubernetes.secret.credentials.data["mimirRemoteWriteAPIUsername"])
      password = remote.kubernetes.secret.credentials.data["mimirRemoteWriteAPIPassword"]
    }
    headers = {
      "X-Scope-OrgID" = "tenant1",
    }
    tls_config {
      insecure_skip_verify = false
    }
    queue_config {
      capacity             = 30000
      max_samples_per_send = 150000
      max_shards           = 10
      sample_age_limit     = "30m"
    }
  }
  wal {
    truncate_frequency = "1m0s"
  }
  external_labels = {
    "cluster_id" = "single-tenant-cluster",
    "cluster_type" = "workload_cluster",
    "customer" = "dummy-customer",
    "installation" = "dummy-cluster",
    "organization" = "dummy-org",
    "pipeline" = "dummy-pipeline",
    "provider" = "capz",
    "region" = "dummy-region",
    "service_priority" = "highest",
  }
}


