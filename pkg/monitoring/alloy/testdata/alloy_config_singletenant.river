logging {
  level  = "info"
  format = "logfmt"
}

prometheus.operator.servicemonitors "giantswarm_legacy" {
  forward_to = [prometheus.remote_write.giantswarm.receiver]
  selector {
    match_expression {
      key      = "application.giantswarm.io/team"
      operator = "Exists"
    }
    match_expressions {
      key      = "observability.giantswarm.io/tenant"
      operator = "DoesNotExist"
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    replacement  = "giantswarm"
    target_label = "giantswarm_observability_tenant"
  }
}

prometheus.operator.podmonitors "giantswarm_legacy" {
  forward_to = [prometheus.remote_write.giantswarm.receiver]
  selector {
    match_expression {
      key      = "application.giantswarm.io/team"
      operator = "Exists"
    }
    match_expressions {
      key      = "observability.giantswarm.io/tenant"
      operator = "DoesNotExist"
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    replacement  = "giantswarm"
    target_label = "giantswarm_observability_tenant"
  }
}

prometheus.operator.servicemonitors "giantswarm" {
  forward_to = [
    prometheus.remote_write.tenant1.receiver,
  ]
  selector {
    match_expression {
      key      = "observability.giantswarm.io/tenant"
      operator = "In"
      values   = [
        tenant1,
      ]
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    source_labels  = ["observability.giantswarm.io/tenant"]
    target_label = "giantswarm_observability_tenant"
  }
}

prometheus.operator.podmonitors "giantswarm" {
  forward_to = [
    prometheus.remote_write.tenant1.receiver,
  ]
  selector {
    match_expression {
      key      = "observability.giantswarm.io/tenant"
      operator = "In"
      values   = [
        tenant1,
      ]
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    source_labels  = ["observability.giantswarm.io/tenant"]
    target_label = "giantswarm_observability_tenant"
  }
}

// remote write pipeline configuration for tenant tenant1
prometheus.relabel "tenant1" {
  forward_to = [prometheus.remote_write.tenant1.receiver]
  // keep only the metrics that have the tenant tenant1
  rule {
    action        = "keep"
    source_labels = ["giantswarm_observability_tenant"]
    regex         = "^tenant1$"
  }

  // drop the tenant label to not have it ingested in mimir
  rule {
    action        = "labeldrop"
    source_labels = ["giantswarm_observability_tenant"]
  }
}

prometheus.remote_write "tenant1" {
  endpoint {
    url            = env("REMOTE_WRITE_URL")
    name           = env("REMOTE_WRITE_NAME")
    enable_http2   = false
    remote_timeout = "60s"
    basic_auth {
      username = env("BASIC_AUTH_USERNAME")
      password = env("BASIC_AUTH_PASSWORD")
    }
    headers = {
      "X-Scope-OrgID" = "tenant1",
    }
    tls_config {
      insecure_skip_verify = false
    }
    queue_config {
      capacity             = 30000
      max_shards           = 10
      max_samples_per_send = 150000
      sample_age_limit     = "30m"
    }
  }
  wal {
    truncate_frequency = "1m0s"
  }
  external_labels = {
    "cluster_id" = "single-tenant-cluster",
    "cluster_type" = "workload_cluster",
    "customer" = "dummy-customer",
    "installation" = "dummy-cluster",
    "organization" = "dummy-org",
    "pipeline" = "dummy-pipeline",
    "provider" = "capz",
    "region" = "dummy-region",
    "service_priority" = "highest",
  }
}

