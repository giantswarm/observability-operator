logging {
  level  = "info"
  format = "logfmt"
}

prometheus.operator.servicemonitors "giantswarm_legacy" {
  forward_to = [prometheus.remote_write.giantswarm.receiver]
  selector {
    match_expression {
      key      = "application.giantswarm.io/team"
      operator = "Exists"
    }
    match_expressions {
      key      = "observability.giantswarm.io/tenant"
      operator = "DoesNotExist"
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    replacement  = "{{ .DefaultTenantID }}"
    target_label = "giantswarm_observability_tenant"
  }
}

prometheus.operator.podmonitors "giantswarm_legacy" {
  forward_to = [prometheus.remote_write.giantswarm.receiver]
  selector {
    match_expression {
      key      = "application.giantswarm.io/team"
      operator = "Exists"
    }
    match_expressions {
      key      = "observability.giantswarm.io/tenant"
      operator = "DoesNotExist"
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    replacement  = "{{ .DefaultTenantID }}"
    target_label = "giantswarm_observability_tenant"
  }
}

prometheus.operator.servicemonitors "giantswarm" {
  forward_to = [
    {{- range .Tenants }}
    prometheus.remote_write.{{ . }}.receiver,
    {{- end }}
  ]
  selector {
    match_expression {
      key      = "observability.giantswarm.io/tenant"
      operator = "In"
      values   = [
        {{- range .Tenants }}
        {{ . }},
        {{- end }}
      ]
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    source_labels  = ["observability.giantswarm.io/tenant"]
    target_label = "giantswarm_observability_tenant"
  }
}

prometheus.operator.podmonitors "giantswarm" {
  forward_to = [
    {{- range .Tenants }}
    prometheus.remote_write.{{ . }}.receiver,
    {{- end }}
  ]
  selector {
    match_expression {
      key      = "observability.giantswarm.io/tenant"
      operator = "In"
      values   = [
        {{- range .Tenants }}
        {{ . }},
        {{- end }}
      ]
    }
  }
  scrape {
    default_scrape_interval = "60s"
  }
  clustering {
    enabled = true
  }
  rule {
    action       = "replace"
    source_labels  = ["observability.giantswarm.io/tenant"]
    target_label = "giantswarm_observability_tenant"
  }
}

{{ range .Tenants -}}
// remote write pipeline configuration for tenant {{ . }}
prometheus.relabel "{{ . }}" {
  forward_to = [prometheus.remote_write.{{.}}.receiver]
  // keep only the metrics that have the tenant {{ . }}
  rule {
    action        = "keep"
    source_labels = ["giantswarm_observability_tenant"]
    regex         = "^{{ . }}$"
  }

  // drop the tenant label to not have it ingested in mimir
  rule {
    action        = "labeldrop"
    source_labels = ["giantswarm_observability_tenant"]
  }
}

prometheus.remote_write "{{ . }}" {
  endpoint {
    url            = env("{{ $.RemoteWriteURLEnvVarName }}")
    name           = env("{{ $.RemoteWriteNameEnvVarName }}")
    enable_http2   = false
    remote_timeout = "{{ $.RemoteWriteTimeout }}"
    basic_auth {
      username = env("{{ $.RemoteWriteBasicAuthUsernameEnvVarName }}")
      password = env("{{ $.RemoteWriteBasicAuthPasswordEnvVarName }}")
    }
    headers = {
      "X-Scope-OrgID" = "{{ . }}",
    }
    tls_config {
      insecure_skip_verify = {{ $.RemoteWriteTLSInsecureSkipVerify }}
    }
    queue_config {
      capacity             = {{ $.QueueConfigCapacity }}
      max_shards           = {{ $.QueueConfigMaxShards }}
      max_samples_per_send = {{ $.QueueConfigMaxSamplesPerSend }}
      sample_age_limit     = "{{ $.QueueConfigSampleAgeLimit }}"
    }
  }
  wal {
    truncate_frequency = "{{ $.WALTruncateFrequency }}"
  }
  external_labels = {
    {{- range $key, $value := $.ExternalLabels }}
    "{{ $key }}" = "{{ $value }}",
    {{- end }}
  }
}

{{ end -}}
