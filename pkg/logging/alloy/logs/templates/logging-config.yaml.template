# This file was generated by observability-operator.
# It configures Alloy to be used as a logging agent.
# - configMap is generated from logging.alloy.template and passed as a string
#   here and will be created by Alloy's chart.
# - Alloy runs as a daemonset, with required tolerations in order to scrape logs
#   from every machine in the cluster.
# - Running as root user is required in order to be able to read log files within
#   /run/log/journal directories.
# - NODE_NAME env var is used as additional label for kubernetes_audit logs.
networkPolicy:
  cilium:
    egress:
    - toEntities:
      - kube-apiserver
      - world
    - toEndpoints:
      - matchLabels:
          io.kubernetes.pod.namespace: kube-system
          k8s-app: coredns
      - matchLabels:
          io.kubernetes.pod.namespace: kube-system
          k8s-app: k8s-dns-node-cache
      toPorts:
      - ports:
        - port: "1053"
          protocol: UDP
        - port: "1053"
          protocol: TCP
        - port: "53"
          protocol: UDP
        - port: "53"
          protocol: TCP
    {{- if not .IsWorkloadCluster }}
    # Allow direct access to loki-backend, loki-gateway and nginx
    - toEndpoints:
      - matchLabels:
          app.kubernetes.io/component: gateway
          app.kubernetes.io/name: loki
          io.kubernetes.pod.namespace: loki
      toPorts:
      - ports:
        - port: "80"
          protocol: TCP
        - port: "8080"
          protocol: TCP
    - toEndpoints:
      - matchLabels:
          app.kubernetes.io/component: backend
          app.kubernetes.io/name: loki
          io.kubernetes.pod.namespace: loki
      toPorts:
      - ports:
        - port: "3100"
          protocol: TCP
    - toEndpoints:
      - matchLabels:
          app.kubernetes.io/name: ingress-nginx
      toPorts:
      - ports:
        - port: "80"
          protocol: ANY
        - port: "443"
          protocol: ANY
    {{- end }}
    {{- if not .NodeFilteringEnabled }}
    # Allow clustering
    - toEndpoints:
      - matchLabels:
          app.kubernetes.io/instance: alloy-logs
          app.kubernetes.io/name: alloy
      toPorts:
      - ports:
        - port: "12345"
          protocol: TCP
    {{- end }}
  endpointSelector:
    matchLabels:
      app.kubernetes.io/instance: alloy-logs
      app.kubernetes.io/name: alloy

alloy:
  alloy:
    configMap:
      create: true
      content: |-
        {{ .AlloyConfig | nindent 8 | replace "        \n" "" | trim }}
    clustering:
      enabled: {{ not .NodeFilteringEnabled }}
      name: alloy-logs
    extraEnv:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    mounts:
      varlog: true
      dockercontainers: true
      extra:
      - name: runlogjournal
        mountPath: /run/log/journal
        readOnly: true
      # This is needed to allow alloy to create files when using readOnlyRootFilesystem
      - name: alloy-tmp
        mountPath: /tmp/alloy
    # We decided to configure the alloy-logs resources as such after some investigation done https://github.com/giantswarm/giantswarm/issues/32655
    resources:
      limits:
        cpu: 2000m
        memory: 300Mi
      requests:
        cpu: 25m
        memory: 200Mi
    securityContext:
      {{- if .NetworkMonitoringEnabled }}
      allowPrivilegeEscalation: true
      appArmorProfile:
        type: Unconfined
      capabilities:
        add:
        - BPF
        - CHECKPOINT_RESTORE
        - DAC_READ_SEARCH
        - NET_RAW
        - NET_ADMIN
        - PERFMON
        - SYS_PTRACE
        - SYS_RESOURCE
        - SYS_ADMIN
        drop: []
      privileged: true
      {{- else }}
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      {{- end }}
      readOnlyRootFilesystem: true
      runAsUser: 0
      runAsGroup: 0
      runAsNonRoot: false
      seccompProfile:
        {{- if .NetworkMonitoringEnabled }}
        type: Unconfined
        {{- else }}
        type: RuntimeDefault
        {{- end }}
  controller:
    type: daemonset
    {{- if .NetworkMonitoringEnabled }}
    hostPID: true
    hostNetwork: true
    {{- end }}
    priorityClassName: {{ .PriorityClassName }}
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    volumes:
      extra:
      - name: runlogjournal
        hostPath:
          path: /run/log/journal
      - name: alloy-tmp
        emptyDir: {}
  {{- if .AlloyImageTag }}
  image:
    tag: {{ .AlloyImageTag }}
  {{- end }}
  {{- if .NetworkMonitoringEnabled }}
  extraObjects:
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      labels:
        observability.giantswarm.io/tenant: {{ .DefaultWriteTenant }}
      name: alloy-logs-beyla
      namespace: kube-system
    spec:
      endpoints:
      - honorLabels: true
        port: http-metrics
        path: /api/v0/component/beyla.ebpf.default/metric
        scheme: http
      selector:
        matchLabels:
          app.kubernetes.io/instance: alloy-logs
          app.kubernetes.io/name: alloy
  {{- end }}

verticalPodAutoscaler:
  enabled: true
  # We decided to configure the alloy-logs vertical pod autoscaler as such after some investigation done https://github.com/giantswarm/giantswarm/issues/32655
  resourcePolicy:
    containerPolicies:
    - containerName: alloy
      controlledResources:
      - memory
      controlledValues: "RequestsAndLimits"
      maxAllowed:
        memory: 1Gi

{{- if .IsWorkloadCluster }}
{{- if gt (len (.DefaultWorkloadClusterNamespaces | join ",")) 0 }}
podLogs:
- name: default-namespaces
  namespace: kube-system
  spec:
    selector: {}
    namespaceSelector:
      matchExpressions:
      - key: kubernetes.io/metadata.name
        operator: In
        values:
        {{- range .DefaultWorkloadClusterNamespaces }}
        - {{ . }}
        {{- end }}
    relabelings:
    - action: replace
      targetLabel: "giantswarm_observability_tenant"
      replacement: {{ .DefaultWriteTenant }}
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
      targetLabel: "app_kubernetes_io_name"
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_component"]
      targetLabel: "app_kubernetes_io_component"
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_version"]
      targetLabel: "app_kubernetes_io_version"
- name: customers-logs
  namespace: kube-system
  spec:
    selector:
      matchExpressions:
      - key: observability.giantswarm.io/tenant
        operator: Exists
    namespaceSelector:
      matchExpressions:
      - key: kubernetes.io/metadata.name
        operator: NotIn
        values:
        {{- range .DefaultWorkloadClusterNamespaces }}
        - {{ . }}
        {{- end }}
    relabelings:
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_observability_giantswarm_io_tenant"]
      targetLabel: "giantswarm_observability_tenant"
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
      targetLabel: "app_kubernetes_io_name"
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_component"]
      targetLabel: "app_kubernetes_io_component"
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_version"]
      targetLabel: "app_kubernetes_io_version"
{{- end }}
{{- else }}
podLogs:
- name: all-pods
  namespace: kube-system
  spec:
    selector: {}
    namespaceSelector: {}
    relabelings:
    - action: replace
      targetLabel: "giantswarm_observability_tenant"
      replacement: {{ .DefaultWriteTenant }}
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
      targetLabel: "app_kubernetes_io_name"
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_component"]
      targetLabel: "app_kubernetes_io_component"
    - action: replace
      sourceLabels: ["__meta_kubernetes_pod_label_app_kubernetes_io_version"]
      targetLabel: "app_kubernetes_io_version"
{{- end }}

{{- if .NetworkMonitoringEnabled }}
kyvernoPolicyExceptions:
  enabled: true
  namespace: giantswarm
  exceptions:
  - policyName: restrict-volume-types
    ruleNames:
    - "*"
  - policyName: always-allow-heartbeats-and-all-pipelines-alerts
    ruleNames:
    - "*"
  - policyName: block-k8s-initiator-app-deployment-capa
    ruleNames:
    - "*"
  - policyName: disallow-capabilities
    ruleNames:
    - "*"
  - policyName: disallow-capabilities-strict
    ruleNames:
    - "*"
  - policyName: disallow-host-namespaces
    ruleNames:
    - "*"
  - policyName: disallow-host-path
    ruleNames:
    - "*"
  - policyName: disallow-host-ports
    ruleNames:
    - "*"
  - policyName: disallow-host-process
    ruleNames:
    - "*"
  - policyName: disallow-noisy-policy-contexts
    ruleNames:
    - "*"
  - policyName: disallow-privilege-escalation
    ruleNames:
    - "*"
  - policyName: disallow-privileged-containers
    ruleNames:
    - "*"
  - policyName: disallow-proc-mount
    ruleNames:
    - "*"
  - policyName: disallow-selinux
    ruleNames:
    - "*"
  - policyName: require-emptydir-requests-and-limits
    ruleNames:
    - "*"
  - policyName: require-run-as-non-root-user
    ruleNames:
    - "*"
  - policyName: require-run-as-nonroot
    ruleNames:
    - "*"
  - policyName: restrict-apparmor-profiles
    ruleNames:
    - "*"
  - policyName: restrict-polex-namespaces
    ruleNames:
    - "*"
  - policyName: restrict-policy-kind-wildcards
    ruleNames:
    - "*"
  - policyName: restrict-seccomp
    ruleNames:
    - "*"
  - policyName: restrict-seccomp-strict
    ruleNames:
    - "*"
  - policyName: restrict-sysctls
    ruleNames:
    - "*"
  - policyName: restrict-volume-types
    ruleNames:
    - "*"
{{- end }}
