global:
  resolve_timeout: 5m
  http_config:
    proxy_from_environment: true
  slack_api_url: "https://slack.com/api/chat.postMessage"

templates:
  - notification-template.tmpl
  - url-template.tmpl

route:
  group_by: [alertname, cluster_id, installation, status, team]
  group_interval: 15m
  group_wait: 5m
  repeat_interval: 4h
  receiver: root

  routes:
  - receiver: heartbeat
    matchers:
    - alertname="Heartbeat"
    continue: true
    group_wait: 30s
    group_interval: 30s
    repeat_interval: 15m

  {{- if eq .Values.managementCluster.pipeline "stable-testing" }}
  - receiver: blackhole
    matchers:
    - cluster_type="workload_cluster"
    continue: false
  - receiver: blackhole
    matchers:
    - cluster_id=~"t-.*"
    continue: false
  - receiver: blackhole
    matchers:
    - alertname=~"ClusterUnhealthyPhase|PrometheusMetaOperatorReconcileErrors|WorkloadClusterApp.*"
    continue: false
  - receiver: blackhole
    matchers:
    - alertname="ClusterUnhealthyPhase"
    - name=~"t-.*"
    continue: false
  # We don't want to get alerts by workload cluster apps that are failing.
  # We select those by checking if the App CR is in a namespace starting with 'org-'.
  - receiver: blackhole
    matchers:
    - alertname="ManagementClusterAppFailed"
    - namespace=~"org-([^g]|g[^i]|gi[^a]|gia[^n]|gian[^t]|giant[^s]|giants[^w]|giantsw[^a]|giantswa[^r]|giantswar[^m])+"
    continue: false
  {{- end }}

  # Falco noise Slack
  - receiver: falco_noise_slack
    matchers:
    - alertname=~"Falco.*"
    continue: false

  - receiver: team_tenet_slack
    repeat_interval: 14d
    matchers:
    - severity=~"notify"
    - team=~"tenet|tinkerers"
    continue: false

  # Team Ops Opsgenie
  - receiver: opsgenie_router
    matchers:
    - severity="page"
    continue: true

  # Team Atlas Slack
  - receiver: team_atlas_slack
    matchers:
    {{- if eq .Values.managementCluster.pipeline "stable" }}
    - severity="notify"
    {{- else }}
    - severity=~"page|notify"
    {{- end }}
    - team="atlas"
    - alertname!~"Inhibition.*"
    - alertname!="Heartbeat"
    continue: false

  # Team Phoenix Slack
  - receiver: team_phoenix_slack
    matchers:
    - team="phoenix"
    - sloth_severity="page"
    - silence="true"
    continue: false

  # Team Shield Slack
  - receiver: team_shield_slack
    matchers:
    - severity=~"page|notify"
    - team="shield"
    continue: false

  # Team Rocket Slack
  - receiver: team_rocket_slack
    matchers:
    - severity=~"page|notify"
    - team="rocket"
    continue: false

  # Team Honeybadger Slack
  - receiver: team_honeybadger_slack
    matchers:
    - severity=~"page|notify"
    - team="honeybadger"
    continue: false

receivers:
- name: root

- name: heartbeat
  webhook_configs:
  - send_resolved: false
    http_config:
      authorization:
        type: GenieKey
        credentials: {{ .Values.monitoring.opsgenieApiKey }}
      follow_redirects: true
      enable_http2: true
      proxy_from_environment: true
    url: https://api.opsgenie.com/v2/heartbeats/{{ .Values.managementCluster.name }}/ping

{{- if eq .Values.managementCluster.pipeline "stable-testing" }}
- name: blackhole
{{- end }}

- name: falco_noise_slack
  slack_configs:
  - channel: '#noise-falco'
    http_config:
      authorization:
        type: Bearer
        credentials: {{ .Values.alerting.slackAPIToken }}
      proxy_from_environment: true
    send_resolved: true
    actions: &slack-actions
    - type: button
      text: ':green_book: Runbook'
      url: '{{`{{ template "__runbook_url" . }}`}}'
      style: '{{`{{ if eq .Status "firing" }}primary{{ else }}default{{ end }}`}}'
    - type: button
      text: ':coffin: Linked PMs'
      url: '{{`{{ template "__alert_linked_postmortems" . }}`}}'
    - type: button
      text: ':mag: Query'
      url: '{{`{{ template "__alert_url" . }}`}}'
    - type: button
      text: ':grafana: Dashboard'
      url: '{{`{{ template "__dashboard_url" . }}`}}'
    - type: button
      text: ':no_bell: Silence'
      url: '{{`{{ template "__alert_silence_link" .}}`}}'
      style: '{{`{{ if eq .Status "firing" }}danger{{ else }}default{{ end }}`}}'

- name: team_atlas_slack
  slack_configs:
  {{- if eq .Values.managementCluster.pipeline "stable" }}
  - channel: '#alert-atlas'
  {{- else }}
  - channel: '#alert-atlas-test'
  {{- end }}
    http_config:
      authorization:
        type: Bearer
        credentials: {{ .Values.alerting.slackAPIToken }}
      proxy_from_environment: true
    send_resolved: true
    actions: *slack-actions

- name: team_phoenix_slack
  slack_configs:
  {{- if eq .Values.managementCluster.pipeline "stable" }}
  - channel: '#alert-phoenix'
  {{- else }}
  - channel: '#alert-phoenix-test'
  {{- end }}
    http_config:
      authorization:
        type: Bearer
        credentials: {{ .Values.alerting.slackAPIToken }}
      proxy_from_environment: true
    send_resolved: true
    actions: *slack-actions

- name: team_rocket_slack
  slack_configs:
  {{- if eq .Values.managementCluster.pipeline "stable" }}
  - channel: '#alert-rocket'
  {{- else }}
  - channel: '#alert-rocket-test'
  {{- end }}
    http_config:
      authorization:
        type: Bearer
        credentials: {{ .Values.alerting.slackAPIToken }}
      proxy_from_environment: true
    send_resolved: true
    actions: *slack-actions

- name: team_shield_slack
  slack_configs:
  - channel: '#alert-shield'
    http_config:
      authorization:
        type: Bearer
        credentials: {{ .Values.alerting.slackAPIToken }}
      proxy_from_environment: true
    send_resolved: true
    actions: *slack-actions

- name: team_tenet_slack
  slack_configs:
  - channel: '#alert-tenet'
    http_config:
      authorization:
        type: Bearer
        credentials: {{ .Values.alerting.slackAPIToken }}
      proxy_from_environment: true
    send_resolved: true
    actions: *slack-actions

- name: team_honeybadger_slack
  slack_configs:
  - channel: '#alert-honeybadger'
    http_config:
      authorization:
        type: Bearer
        credentials: {{ .Values.alerting.slackAPIToken }}
      proxy_from_environment: true
    send_resolved: true
    actions: *slack-actions

- name: opsgenie_router
  opsgenie_configs:
  - api_key: {{ .Values.monitoring.opsgenieApiKey }}
    tags: '{{`{{ (index .Alerts 0).Labels.alertname }},{{ (index .Alerts 0).Labels.cluster_type }},{{ (index .Alerts 0).Labels.severity }},{{ (index .Alerts 0).Labels.team }},{{ (index .Alerts 0).Labels.area }},{{ (index .Alerts 0).Labels.service_priority }},{{ (index .Alerts 0).Labels.provider }},{{ (index .Alerts 0).Labels.installation }},{{ (index .Alerts 0).Labels.pipeline }},{{ (index .Alerts 0).Labels.customer }}`}}'

inhibit_rules:
- source_matchers:
  - inhibit_kube_state_metrics_down=true
  target_matchers:
  - cancel_if_kube_state_metrics_down=true
  equal: [cluster_id]

- source_matchers:
  - cluster_control_plane_unhealthy=true
  target_matchers:
  - cancel_if_cluster_control_plane_unhealthy=true
  equal: [cluster_id]

- source_matchers:
  - cluster_control_plane_unhealthy=true
  target_matchers:
  - cancel_if_any_cluster_control_plane_unhealthy=true

- source_matchers:
  - kubelet_down=true
  target_matchers:
  - cancel_if_kubelet_down=true
  equal: [cluster_id, ip]

- source_matchers:
  - control_plane_node_down=true
  target_matchers:
  - cancel_if_control_plane_node_down=true
  equal: [cluster_id]

- source_matchers:
  - outside_working_hours=true
  target_matchers:
  - cancel_if_outside_working_hours=true

- source_matchers:
  - has_worker_nodes=false
  target_matchers:
  - cancel_if_cluster_has_no_workers=true
  equal: [cluster_id]

- source_matchers:
    - inhibit_monitoring_agent_down=true
  target_matchers:
    - cancel_if_monitoring_agent_down=true
  equal: [cluster_id]

# Source: https://github.com/giantswarm/prometheus-rules/blob/main/helm/prometheus-rules/templates/kaas/tenet/alerting-rules/inhibit.nodes.rules.yml
- source_matchers:
    - node_not_ready=true
  target_matchers:
    - cancel_if_node_not_ready=true
  equal: [cluster_id, node]

# Source: https://github.com/giantswarm/prometheus-rules/blob/main/helm/prometheus-rules/templates/kaas/tenet/alerting-rules/inhibit.nodes.rules.yml
- source_matchers:
    - node_unschedulable=true
  target_matchers:
    - cancel_if_node_unschedulable=true
  equal: [cluster_id, node]
